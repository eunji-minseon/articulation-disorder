import cv2
import mediapipe as mp
import numpy as np

# MediaPipe ì´ˆê¸°í™” (ê°œì„ ëœ ì„¤ì •)
mp_face_mesh = mp.solutions.face_mesh

# ì…ìˆ  ê´€ë ¨ landmark index 
LIPS_IDX = sorted(set([
    61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291,     # ìœ—ì…ìˆ 
    146, 91, 181, 84, 17, 314, 405, 321, 375             # ì•„ë«ì…ìˆ 
]))

class CoordinateSmoothing:
    """ì¢Œí‘œ ìŠ¤ë¬´ë”©ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    def __init__(self, alpha=0.7):
        self.alpha = alpha
        self.prev_coords = None
    
    def smooth(self, coords):
        if self.prev_coords is None:
            self.prev_coords = coords
            return coords
        
        # ì§€ìˆ˜ ì´ë™ í‰ê· ìœ¼ë¡œ ìŠ¤ë¬´ë”©
        smoothed = []
        for i, (x, y) in enumerate(coords):
            prev_x, prev_y = self.prev_coords[i]
            smooth_x = self.alpha * x + (1 - self.alpha) * prev_x
            smooth_y = self.alpha * y + (1 - self.alpha) * prev_y
            smoothed.append((smooth_x, smooth_y))
        
        self.prev_coords = smoothed
        return smoothed

def enhance_frame_quality(frame):
    """í”„ë ˆì„ í’ˆì§ˆ í–¥ìƒ"""
    # ëª…ë„ ì¡°ì •
    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    
    # CLAHE (Contrast Limited Adaptive Histogram Equalization) ì ìš©
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    
    enhanced = cv2.merge([l, a, b])
    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
    
    return enhanced

def normalize_coordinates(coords, frame_width, frame_height):
    """ì¢Œí‘œ ì •ê·œí™” (0-1 ë²”ìœ„ë¡œ)"""
    normalized = []
    for x, y in coords:
        norm_x = x / frame_width if frame_width > 0 else x
        norm_y = y / frame_height if frame_height > 0 else y
        normalized.append((norm_x, norm_y))
    return normalized

def extract_mouth_landmarks(video_path, output_txt_path):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ì˜ìƒ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
        return

    # ê°œì„ ëœ FaceMesh ì„¤ì •
    face_mesh = mp_face_mesh.FaceMesh(
        static_image_mode=False,
        max_num_faces=1,
        refine_landmarks=True,  # ë” ì •í™•í•œ ëœë“œë§ˆí¬
        min_detection_confidence=0.7,  # ê²€ì¶œ ì‹ ë¢°ë„ ì¦ê°€
        min_tracking_confidence=0.5    # ì¶”ì  ì‹ ë¢°ë„
    )

    # ìŠ¤ë¬´ë”© ê°ì²´ ì´ˆê¸°í™”
    smoother = CoordinateSmoothing(alpha=0.7)
    
    coords_all = []
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    success_count = 0
    
    # í”„ë ˆì„ í¬ê¸° ì •ë³´
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    print(f"ğŸ¬ ì˜ìƒ ë¶„ì„ ì‹œì‘: {video_path}")
    print(f"ğŸ“ í”„ë ˆì„ í¬ê¸°: {frame_width}x{frame_height}")
    print(f"ğŸï¸ ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")

    for frame_idx in range(total_frames):
        ret, frame = cap.read()
        if not ret:
            break

        # í”„ë ˆì„ í’ˆì§ˆ í–¥ìƒ
        enhanced_frame = enhance_frame_quality(frame)
        frame_rgb = cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2RGB)
        
        results = face_mesh.process(frame_rgb)

        if results.multi_face_landmarks:
            landmarks = results.multi_face_landmarks[0]
            
            # ì…ìˆ  ì¢Œí‘œ ì¶”ì¶œ (í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜)
            mouth_coords = []
            for i in LIPS_IDX:
                if i < len(landmarks.landmark):
                    lm = landmarks.landmark[i]
                    x = lm.x * frame_width
                    y = lm.y * frame_height
                    mouth_coords.append((x, y))
            
            if len(mouth_coords) == len(LIPS_IDX):
                # ì¢Œí‘œ ìŠ¤ë¬´ë”© ì ìš©
                smoothed_coords = smoother.smooth(mouth_coords)
                
                # ì •ê·œí™”ëœ ì¢Œí‘œ ì €ì¥ (0-1 ë²”ìœ„)
                normalized_coords = normalize_coordinates(smoothed_coords, frame_width, frame_height)
                coords_all.append(normalized_coords)
                success_count += 1
        else:
            # ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨ ì‹œ ì´ì „ í”„ë ˆì„ ì¢Œí‘œ ì‚¬ìš© (ìˆë‹¤ë©´)
            if coords_all:
                coords_all.append(coords_all[-1])  # ë§ˆì§€ë§‰ ì„±ê³µí•œ ì¢Œí‘œ ì¬ì‚¬ìš©
            
        # ì§„í–‰ë¥  í‘œì‹œ
        if (frame_idx + 1) % 100 == 0:
            progress = (frame_idx + 1) / total_frames * 100
            print(f"â³ ì§„í–‰ë¥ : {progress:.1f}% ({frame_idx + 1}/{total_frames})")

    cap.release()
    face_mesh.close()

    # ê²°ê³¼ ì €ì¥
    with open(output_txt_path, "w", encoding='utf-8') as f:
        for frame_coords in coords_all:
            # ë” ì •í™•í•œ ì¢Œí‘œ ì €ì¥ (ì†Œìˆ˜ì  6ìë¦¬)
            formatted_coords = [(round(x, 6), round(y, 6)) for x, y in frame_coords]
            f.write(str(formatted_coords) + "\n")

    success_rate = (success_count / total_frames) * 100 if total_frames > 0 else 0
    print(f"âœ… ì™„ë£Œ: {output_txt_path}")
    print(f"ğŸ“Š ì„±ê³µë¥ : {success_count}/{total_frames} ({success_rate:.1f}%)")
    print(f"ğŸ’¾ ì €ì¥ëœ í”„ë ˆì„ ìˆ˜: {len(coords_all)}")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    video_path = "your_video.mp4"
    output_path = "mouth_landmarks.txt"
    extract_mouth_landmarks(video_path, output_path)