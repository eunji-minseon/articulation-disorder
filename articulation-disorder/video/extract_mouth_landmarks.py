import cv2
import mediapipe as mp

# MediaPipe ì´ˆê¸°í™”
mp_face_mesh = mp.solutions.face_mesh

# ì…ìˆ  ê´€ë ¨ landmark index 
LIPS_IDX = sorted(set([
    61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291,     # ìœ—ì…ìˆ 
    146, 91, 181, 84, 17, 314, 405, 321, 375             # ì•„ë«ì…ìˆ 
]))

def extract_mouth_landmarks(video_path, output_txt_path):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ì˜ìƒ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
        return

    face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)

    coords_all = []
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    success_count = 0

    for _ in range(total_frames):
        ret, frame = cap.read()
        if not ret:
            break

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = face_mesh.process(frame_rgb)

        if results.multi_face_landmarks:
            landmarks = results.multi_face_landmarks[0]
            mouth_coords = [
                (lm.x, lm.y)
                for i, lm in enumerate(landmarks.landmark)
                if i in LIPS_IDX
            ]
            coords_all.append(mouth_coords)
            success_count += 1

    cap.release()
    face_mesh.close()

    # ê²°ê³¼ ì €ì¥
    with open(output_txt_path, "w") as f:
        for frame_coords in coords_all:
            f.write(str(frame_coords) + "\n")

    print(f"ğŸ“½ï¸ {video_path}: ì´ {total_frames}í”„ë ˆì„ ì¤‘ {success_count}ê°œì—ì„œ ì–¼êµ´ ì¸ì‹ ì„±ê³µ") 